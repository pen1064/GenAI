{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import openai\n",
    "import time\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_BASE =  os.getenv('OPENAI_API_BASE') \n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION') \n",
    "OPENAI_API_TYPE = os.getenv('OPENAI_API_TYPE') \n",
    "\n",
    "openai.api_type = OPENAI_API_TYPE\n",
    "openai.api_base = OPENAI_API_BASE \n",
    "openai.api_version = OPENAI_API_VERSION\n",
    "openai.api_key = OPENAI_API_KEY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 10.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    # Split the text into chunks using Langchain's CharacterTextSplitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=10000,\n",
    "        chunk_overlap=1000,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    # Convert the chunks of text into embeddings to form a knowledge base\n",
    "    embeddings = OpenAIEmbeddings(engine=\"text-embedding-ada-002\") \n",
    "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
    "    \n",
    "    return knowledgeBase\n",
    "\n",
    "text_folder = r'C:\\Users\\pkwong\\OneDrive - Canada Pension Plan Investment Board\\Desktop\\AI\\text'\n",
    "    \n",
    "for fn in os.listdir(text_folder):\n",
    "    pdf_reader = PdfReader(os.path.join(text_folder, fn))\n",
    "    # Text variable will store the pdf text\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Create the knowledge base object\n",
    "    knowledgeBase = process_text(text)\n",
    "    time.sleep(30)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = knowledgeBase.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filing taxes is required by law for most individuals and businesses. The tax money collected is used by the government to fund public services, infrastructure, social programs, defense, and other government functions. If you earn income above a certain threshold, you are required to file a tax return. The specific amount varies based on factors such as your age, filing status, and type of income. Not filing taxes when required can result in penalties and legal consequences.\n"
     ]
    }
   ],
   "source": [
    "query = \"Why do I have to file taxes?\"\n",
    "docs = index.get_relevant_documents(query)\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(temperature=0, verbose=True, deployment_name=\"gpt-4-32k\", openai_api_version=\"2023-07-01-preview\")\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type='stuff')\n",
    "with get_openai_callback() as cost:\n",
    "    response = chain.run(input_documents=docs, question=query)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
